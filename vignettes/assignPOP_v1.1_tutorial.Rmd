---
title: "R package [assignPOP v1.1] tutorial"
author: "Alex Chen"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: yes
    toc_float: yes
  pdf_document: default
  word_document:
    fig_caption: yes
---
The assignPOP package helps perform population assignment using a machine learning framework. It employs [supervised machine learning](https://en.wikipedia.org/wiki/Supervised_learning) methods to evalute the discriminatory power of your known data set, and is capable of analyzing **large genetic, non-genetic, or integrated (genetic plus non-genetic) data sets**. This framework is also designed for solving the upwardly biased issue that was discussed in previous studies (Anderson 2010^[Anderson, E. C. (2010). Assessing the Power of Informative Subsets of Loci for Population Assignment: Standard Methods Are Upwardly Biased. *Molecular Ecology Resources* 10(4): 701–710. doi:10.1111/j.1755-0998.2010.02846.x.]; Waples 2010^[Waples, R. S. (2010). High-Grading Bias: Subtle Problems with Assessing Power of Selected Subsets of Loci for Population Assignment. *Molecular Ecology* 19(13): 2599–2601. doi:10.1111/j.1365-294X.2010.04675.x.]). Other features are listed below.

- Use principle component analysis (PCA) for dimensionality reduction (or data transformation)
- Use Monte-Carlo cross-validation to evaluate the variation of assignment accuracy
- Use *K*-fold cross-validation to estimate membership probability
- Allow to resample training individuals with various proportions or numbers
- Allow to resample training loci with various proportions either randomly or based on locus *F~ST~* value
- Provide several machine learning classifiers, including  LDA, SVM, naive Bayes, decision tree, and random forest to build tunable predictive models.
- Output results in publication-quality plots while being editable using ggplot2 library

***
## Conceptual framework

The ability to assign unknown individuals to source populations relies on a robust baseline collected from the source populations. Therefore, we should evaluate whether the baseline has high assignment accuracy on the known individuals themselves in advance of performing assignment on unknown individuals. The diagram below illustrates how the assignPOP package incorporates into the assignment framework.
```{r, echo=FALSE}
DiagrammeR::grViz("
digraph conceptframe {
node [shape=box, fontname=Arial]
A [label='START:\nEvaluate a baseline collected\nfrom source populations\n(known individuals)']
B [label='Results:\nassignment accuracy\nor\nmembership probability']
C [label='Collect more data (features)\nfrom known individuals']
D [label='Collect unknown individuals\nto be predicted']
E [label='Perform assignment test\non unknown individuals']
F [label='Results:\npredicted populations\nand\nmembership probability']

edge [arrowhead=normal]
A -> B [label='analyze data via assignPOP', fontcolor=firebrick]
B -> C [label='bad results']
B -> D [label='good results']
D -> E 
E -> F [label='analyze data via assignPOP',fontcolor=firebrick]
C -> A [label='re-evaluate']

subgraph { rank=same; C; D; }
subgraph { rank=same; A; E; }
}
", height=350)
```

### Analytical workflow {#analyticalworkflow}

```{r, echo=FALSE}
DiagrammeR::grViz("
digraph evaluatebaseline {
graph [rankdir = LR, ranksep=0.1, nodesep=0.3]
  
  node [shape=box, fontname=Arial]
  A [label='Step 1-1. Import data']
  B [label='Step 1-2.\nPerform resampling\ncross-validation']
  C [label='Step 1-3. Visualize results']
  
  node [shape=plaintext, fontname=Arial]
  1 [label='For genetic data, use\nread.genpop( ), reduce.allele( )']
  2 [label='For non-genetic data, use\nread.table( ), read.csv( )\n*data imported as a data frame']
  3 [label='For integrated data, use\nread.genpop( ), compile.data( )']
  5 [label='Monte-Carlo cross-validation\nassign.MC( )']
  6 [label='K-fold cross-validation\nassign.kfold( )']
  7 [label='Optional: Identify informative loci\ncheck.loci( )']
  8 [label='Assignment accuracy\naccuracy.MC( ), accuracy.kfold( ),\naccuracy.plot( )']
  9 [label='Membership probability\nmembership.plot( )']

  node [shape=plaintext, fontname=Arial, label='Step 1. Evaluate known individuals', fontsize=20]
  TT
  edge [arrowhead=normal]
  A -> B B -> C
  edge [arrowhead=tee]
  A -> 1  B -> 5  C -> 8
  edge [color=transparent]
  TT -> A
  1 -> 2 -> 3  5 -> 6 -> 7  8 -> 9
  edge [arrowhead=normal, color=gray]
  5 -> 7 6 -> 7
  subgraph { rank=same; TT; A; 1; 2; 3;}
  subgraph { rank=same; B; 5; 6; 7;}
  subgraph { rank=same; C; 8; 9;}
}
", height=280)
```

```{r, echo=FALSE}
DiagrammeR::grViz("
digraph assignunknown {
  graph [rankdir = LR, ranksep=0.2, nodesep=0.25]
  node [shape=box, fontname=Arial]
  A [label='Step 2-1. Import data']
  B [label='Step 2-2. Perform assignment\ntest and visualize results']
  
  node [shape=plaintext, fontname=Arial]
  1 [label='Use read.genpop( ), compile.data( ),\nread.table( ), or read.csv( )']
  2 [label='Known and unknown data sets\nshould be imported separately']
  5 [label='Use assign.X( )']
  6 [label='Output results and\ngenerate membership\nprobability plot']
  
  node [shape=plaintext, fontname=Arial, fontsize=20]
  TT [label='Step 2. Assign unknown individuals']
  
  edge [arrowhead=normal]
  A -> B
  5 -> 6
  edge [arrowhead=tee]
  A -> 1 
  B -> 5
  edge [arrowhead=none, color=transparent]
  TT -> A
  1 -> 2
  B -> 5
  subgraph {rank=same; TT; A; 1; 2;}
  subgraph {rank=same; B; 5; 6}
}          
", height=200)

```

***
## Install and import assignPOP

To install the package from CRAN, type:

```{r install package from CRAN, eval=FALSE}
install.packages("assignPOP")
```

Alternatively, you can install the package from the Github repository, but it requires you to install the [devtools] package first.

```{r intall package from Github, eval=FALSE}
install.packages("devtools")
library(devtools)
install_github("alexkychen/assignPOP")
```

To import the package to your R environment, type:

```{r import the package, include=TRUE}
library(assignPOP)
```

***
## Prepare and import data

### Prepare and import genetic data of source populations

Currently, assignPOP accepts genetic data in GENEPOP format (Rousset 2008^[Rousset, F. (2008). genepop’007: A Complete Re-Implementation of the Genepop Software for Windows and Linux. *Molecular Ecology Resources* 8(1): 103–106. doi:10.1111/j.1471-8286.2007.01931.x.]), a commonly used format in molecular ecology studies. GENEPOP has two forms, and both forms are accepted by assignPOP. For details about GENEPOP format, please visit <http://genepop.curtin.edu.au/help_input.html>. 

To import a GENEPOP file, use the function `read.genpop()` and provide a return object name (e.g., `genin`) as follows. 

```{r read a genepop file, eval=FALSE}
genin <- read.genpop( "simGenepop.txt", pop.names=c("pop_A","pop_B","pop_C") )
```

The example input file, [*simGenepop.txt*](https://raw.githubusercontent.com/alexkychen/assignPOP/master/inst/extdata/simGenepop.txt), contains **three** simulated populations (or subpopulations) and each population has 30 individuals by 1,000 SNP loci. You can use the argument `pop.names` to name your populations in your GENEPOP (must follow the group order^[The name order in the argument `pop.names` should match the group order in your GENEPOP file. For example, the first name, `pop_A`, in `pop.names=c("pop_A","pop_B","pop_C")` is the top first group (pop) of samples in the GENEPOP.]) so that later you can customize assignment accuracy plots by specifying these names.

After importing the file, you should see the following message printed in your R console. Use this information to double check your data was correctly imported.

```{r print file message, echo=FALSE}
cat("############### assignPOP v1.1 ###############\n
A GENEPOP format file was successfully imported!\n
DataInfo: 90 obs. by 1000 loci (with 2000 var.)\
DataMatrix: 90 rows by 2001 columns\
Number of pop:3\
Number of inds (pop_A): 30\
Number of inds (pop_B): 30\
Number of inds (pop_C): 30\n
Data output in a list comprising the following three elements:\
DataMatrix @ YOUR_LIST_NAME[[1]]\
IndividualNames @ YOUR_LIST_NAME[[2]]\
LocusNames @ YOUR_LIST_NAME[[3]]")
```

### Import genetic data of unknown individuals

When assigning unknown individuals (see Step 2 in [Analytical workflow](#analyticalworkflow)), you will first import a GENEPOP file that includes known individuals (for building predictive models), and then import another GENEPOP that includes unknown individuals. All unknown individuals in your GENEPOP should be saved in one single group, meaning that you will have only one 'pop' label in the file. Again, use `read.genpop()` to import the file and ignore the argument `pop.names`, but make sure you provide different object names for known and unknown data sets.

```{r, eval=FALSE}
# Import a GENEPOP file containing unknown individuals
genin_unknown <- read.genpop( "simGenepopX.txt" )
```

### Remove low variance loci (optional)

For a very large data file (e.g, tens of thousands of loci), you can choose to remove loci that have low variance^[A low variance locus is one in which a single (major) allele occurs in most individuals, with an alternate (minor) allele occuring in only a few individuals. Removal of these low variance loci will help avoid the problem of a minor allele ending up being assigned to either only training or only test sets. For example, if 9 out of 10 individuals have the same genotype (e.g., AA, A is major allele) and only 1 individual has the minor allele (e.g., Aa, a is minor allele with 0.05 frequency), the locus will not help predict the group of individuals regardless of whether the rare Aa individul is assigned to a training or test set. Therefore, removal of low variance loci does not influence results but helps accelerate post analyses.] across the data set in advance of further analyses. The default of variance threshold is 0.95, meaning that any locus with a major allele occuring in over 95% of individuals across all populations will be removed from the data set. 

To remove low variance loci, use the following function and provide a new object name (e.g., `genin_rd`) : 

```{r reduce loci, eval=FALSE}
genin_rd <- reduce.allele(genin, p = 0.95)
```

After entering the code, R console should print the following message. 

```{r print reduce.allele message, echo=FALSE}
cat("New data matrix has created! :)\
New DataMatrix size: 90 rows by 1387 columns\
614 columns (alleles) have been removed\
693 loci remain")
```

In our example, 307 low variance loci^[In this case, we have 614 alleles across 307 loci, meaning that every locus is biallelic (307 loci x 2 alleles = 614 alleles)] were removed, leaving 693 loci in the new data set, which will be used in further analyses.

### Concatenate genetic and non-genetic data

A novel feature of the package is that it can integrate genetic and non-genetic data for population assignment tests. After importing your GENEPOP file, you can use the function `compile.data()` to concatenate a non-genetic data set and the genetic matrix that was returned from either `read.genpop()` or `reduce.allele()`. Your non-genetic data should be saved in a .csv file (elements separated by commas) or table-like text file (elements separated by spaces) in which the first column must be sample IDs that match the IDs in your GENEPOP file, and the rest of columns are non-genetic data, whether it is numeric or categorical. If a sample ID exists in only one of the data sets, the individual will be ignored in the new integrated data. 

To concatenate data, use the following function and provide a new object name (e.g., `comin`):

```{r run compile.data, eval=FALSE}
comin <- compile.data(genin_rd, "morphData.csv")
```

The above [*morphData.csv*](https://raw.githubusercontent.com/alexkychen/assignPOP/master/inst/extdata/morphData.csv) file has the same individuals as in [*simGenepop.txt*](https://raw.githubusercontent.com/alexkychen/assignPOP/master/inst/extdata/simGenepop.txt) and contains 4 numeric variables (morphormetric measurements) for each individual. After executing the function, it will prompt the following message and wait for your answer to verify the data type (numeric or categorical). 

```{r print compile.data dialogue, echo=FALSE, collapse=TRUE}
cat("Import a .CSV file.\
4 additional variables detected.\
Checking variable data type...\
 D1.2(integer)  D2.3(integer)  D3.4(integer)  D1.4(integer)")
ans <- readline(" Are they correct? (enter Y/N): ")
```

If a variable is categorical, it will automatically convert it to new [dummy variables](https://en.wikipedia.org/wiki/Dummy_variable_(statistics)) using [model.matrix()](https://stat.ethz.ch/R-manual/R-devel/library/stats/html/model.matrix.html) so that the categorical data can be quantified for further analyses. If your data type was incorrectly identified, simply enter **N** and then follow the prompted dialogue to change your data type. If your data type was correctly identified (entry is **Y** in this example), then it will print the following message.

```{r print compile.data message, echo=FALSE}
cat("New data set created!!\
It has 90 observations by 1391 variables\
including 693 loci(1386 alleles) plus 4 additional variables(4 columns)")

```

If you are evaluating a baseline using integrated data, the return object (e.g., `comin`) will be used in resampling cross-validation. On the other hand, if you are assigning unknown individuals, be sure to run the function `compile.data()` for known and unknown data sets, respectively, and provide different return object names. These two objects will be used in the assignment test (`assign.X()`). 

### Prepare and import non-genetic data

In addition to analyzing genetic and integrated data, you can perform assignment tests using only non-genetic data. This allows you to compare the results between data types. A non-genetic data set for baseline evaluation should include 1) sample IDs in the first column, 2) population label^[A column includes population names for each individual. Also be sure to include a column name in table header.] in the last column, and 3) features in columns between the first and last column. The file should be saved in a .csv (comma dilimited) or table-like text file that can be read into R using `read.csv()` or `read.table()`. For example, if we are going to perform assignment test using the morphormetric data ([*morphData.csv*](https://raw.githubusercontent.com/alexkychen/assignPOP/master/inst/extdata/morphData.csv)) alone, we would need to add a population column after the last feature column. It can be done by either manually editing the file or adding a column after the file was imported (as shown below).

```{r, eval=FALSE}
#Import morphormetric data containing sample IDs and features
morphdf <- read.csv( "morphData.csv", header=TRUE )
#Create a string vector for population label (repeat each name for 30 individuals)
pop_label <- c( rep("pop_A", 30), rep("pop_B", 30), rep("pop_C", 30) ) 
#Add the pop_label to the last column; 'morphdf_pop' is a data frame with population label in the last column
morphdf_pop <- cbind(morphdf, pop_label)
```

A non-genetic data containing the population label could be used for baseline evaluation or as a baseline to predict unknown individuals. In other words, when performing an assignment test on unknown individuals using non-genetic data alone, the population column should be included in the known data set but not in the unknown data set. 

***
## Perform population assignment 

To evaluate discriminatory power of a baseline, the package uses Monte-Carlo cross-validation (function `assign.MC()`) to estimate assignment accuracies over all populations and for each population, and uses *K*-fold cross-validation (function `assign.kfold()`) to estimate membership probabilities across all individuals. [About Monte-Carlo and *K*-fold cross-validation](http://stats.stackexchange.com/questions/51416/k-fold-vs-monte-carlo-cross-validation)  

### Monte-Carlo cross-validation for baseline evaluation

When performing Monte-Carlo cross-validation using genetic or integrated data, users can specify multiple proportions or multiple fixed numbers of individuals from each population to be used as training individuals (arg. `train.inds`) and multiple porportions of loci to be used as training loci (arg. `train.loci`). A set of training loci can be chosen either randomly (arg. `loci.sample="random"`) or based on locus *F~ST~* estimated within training individuals (arg. `loci.sample="fst"`). Each combination of training individuals and loci can be resampled multiple times (arg. `iterations`). For example, the following code performs a total of 360 assignment tests, sampling 50%, 70% and 90% of individuals randomly from each population, using the highest 10%, 25%, 50% of *F~ST~* loci as well as all loci for the training data. Each sample size combination was resampled 30 times.

```{r run assign.MC, eval=FALSE}
assign.MC(genin_rd, train.inds=c(0.5, 0.7, 0.9), train.loci=c(0.1, 0.25, 0.5, 1), 
          loci.sample="fst", iterations=30, dir="Result-folder/", model="svm" )
```

To use certain numbers, rather than proportions, of individuals from each population as training data, enter positive integers in the argument `train.inds`.

If you are analyzing non-genetic data alone, the arguments, `train.loci` and `loci.sample`, will be automatically ignored. 

The results will be saved in a folder created via the argument `dir`. In the above example, a folder named "Result-folder" is created and results are saved in it. You must include a forward slash (/) at the end of your folder name. 

In addition, you can use the argument `model` to select a classifier for prediction. In this case, the [Support Vector Machine (SVM)](https://en.wikipedia.org/wiki/Support_vector_machine) classifier is used. Other SVM related arguments, `svm.kernel` and `svm.cost`, can be specified to fine tune the predictive model. See the [e1071](https://cran.r-project.org/web/packages/e1071/index.html) package for details about SVM. Other classifiers, including [LDA](https://en.wikipedia.org/wiki/Linear_discriminant_analysis), [naive Bayes](https://en.wikipedia.org/wiki/Naive_Bayes_classifier), [decision tree](https://en.wikipedia.org/wiki/Decision_tree), and [random forest](https://en.wikipedia.org/wiki/Random_forest), can be used to build predictive models. Type `?assign.MC` to see details.

### *K*-fold cross-validation for baseline evaluation

While Monte-Carlo cross-validation helps evaluate variation in assignment accuracy through resampling, it does not guarantee that every individual was tested, and multiple tests on an individual also makes it difficult to estimate membership probabilities across individuals and populations. As such, we introduced *K*-fold cross-validation to help estimate membership probability because it gurantees that every individual will be tested once while none of them will be used as training and test individuals in the same test. To perform *K*-fold cross-validation, use the following function:

```{r run assign.kfold, eval=FALSE}
assign.kfold(genin_rd, k.fold=c(3, 4, 5), train.loci=c(0.1, 0.25, 0.5, 1), 
             loci.sample="random", dir="Result-folder2/", model="lda" )
```

In the *K*-fold cross-validation, rather than specifying the proportions of individuals to be sampled, use the argument `k.fold` to specify the number of groups to divide each population into. The above example divides individuals from each population into 3, 4, or 5 groups. Within each fold, 10%, 25% and 50% of random loci (arg. `loci.sample = "random"`), as well as all loci, were sampled for training data (arg. `train.loci`). As such, the *K*-fold cross-validation performs a total of 48 assignment tests (N = (3+4+5)*4 tests).

When analyzing non-genetic data alone, the arguments, `train.loci` and `loci.sample`, will be automatically ignored.

To most efficiently compute the analyses, by default, all available cores/threads minus one (N-1) of your computer's CPU are used for parallel analyses so that multiple assignment tests are performed simultaneously (assuming the computer has a multi-core CPU). To change the number of cores/threads used, simply specify a number in the argument `processors`. 

Depending on the size of your dataset, running `assign.MC()` may take a few minutes to hours; `assign.kfold()` is usually quicker because of fewer tests. You can monitor the analysis status by counting the output files in the result folder.

### Assign unknown individuals

In addition to evaluting a known data set, the package also provides a function `assign.X()` that allows you to perform an assignment test on unknown individuals using the known data that was evaluated (assuming the results are satisfactory). After importing your known and unknown data sets (they should be the same data type and have same feature names), use the arguments `x1` and `x2` to specify the known and unknown data, respectively. 

```{r, eval=FALSE}
# Perform an assignment test using decision tree as the predictive model
assign.X( x1=genin, x2=genin_unknown, dir="Result-folder3/", model="tree")

# Use `?assign.X` to see other argument settings.
```

The assignment result will be saved in a text file named *AssignmentResult.txt* under the designated folder. This file includes sample IDs of your unknown individuals, predicted populations and the probabilities. When the assignment is done, it will prompt a message asking you whether a membership probability plot should be generated. You can enter **Y** to visualize the result right away.  

### PCA for data transformation

The assignment functions, `assign.MC()`, `assign.kfold()` and `assign.X()`, use PCA for dimensionality reduction. It converts your independent variables to Principle Components and retain the PCs that have eigenvalues greater than 1 (the Kaiser-Guttman criterion) as new features (arg. `pca.PCs="kaiser-guttman"`). Or, you can specify an integer in the argument `pca.PCs` (e.g., `pca.PCs = 10`) to choose a specific number of PCs to be retained. 

The PCA will always perform on the genetic data, whether you are analyzing genetic-only or integrated data. When analyzing integrated data, you have three options to perform PCA on the data. First, you can perform PCA across all features (set arg. `pca.method="mixed"`), meaning that each PC includes information of genetic and non-genetic data. This is default setting. Second, you can perform PCA on genetic and non-genetic data indpendently (set arg. `pca.method="independent"`), meaning that your transformed data includes genetic PCs and non-genetic PCs. Third, you can choose to use original non-genetic data as features without peforming PCA on them (set. arg. `pca.method="original"`). This option ends up using genetic PCs and original non-genetic data to build predictive models. 

When analyzing non-genetic data alone, you can determine whether PCA is performed on the data. You set the argument `pca.method=TRUE` to perform PCA, or `pca.method=FALSE` to not perform PCA. 

***
## Visualize results

### Assignment accuracy

### Membership probability

***
## Identify informative loci

***
## References and footnotes

